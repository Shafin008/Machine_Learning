{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98589494",
   "metadata": {},
   "source": [
    "### 1: Voting and Averaging\n",
    "\n",
    "##### Voting:\n",
    "- Voting combines the predictions of individual models using the mode. \n",
    "- As the mode is a categorical measure, Voting can only be applied to Classification. \n",
    "- Voting is heterogeneous, as the individual models are from different algorithms. \n",
    "\n",
    "##### Averaging:\n",
    "- The Averaging method combines the individual predictions using the mean. \n",
    "- In contrast to Voting, Averaging can be applied on both classification and regression. \n",
    "- Like Voting, Averaging is also heterogeneous. \n",
    "\n",
    "#### When to choose them:\n",
    "\n",
    "- Both techniques are good choices when you have already built multiple different models for the same problem. \n",
    "\n",
    "- Also, if you are not sure which will perform better on unseen data. \n",
    "\n",
    "- Or simply you want to improve the overall performance by combining your existing models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea16c9a",
   "metadata": {},
   "source": [
    "### 2: Weak Estimator and Bagging\n",
    "\n",
    "##### Weak Estimator:\n",
    "\n",
    "- \"Weak\" estimator, one which performs just better than random guessing. \n",
    "\n",
    "- It must also be light and fast.\n",
    "\n",
    "- \"Weak\" estimators are the building blocks for homogeneous ensemble methods, in which all the individual estimators use the same algorithm. \n",
    "\n",
    "##### Bagging, or Bootstrap Aggregating:\n",
    "\n",
    "- The bootstrapping technique draw random subsamples with replacement. \n",
    "\n",
    "- A large amount of \"weak\" estimators are trained with those subsamples, which predictions are then aggregated by Voting or Averaging. \n",
    "\n",
    "- Bagging is a homogeneous ensemble method. \n",
    "\n",
    "#### When to choose:\n",
    "\n",
    "- Bagging is a good choice when you want to reduce variance on the predictions.\n",
    "\n",
    "- Also if you want to prevent over-fitting. \n",
    "\n",
    "- Or if you need more stability and robustness with unseen data. \n",
    "\n",
    "- Keep in mind that Bagging is computationally expensive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21ec7de",
   "metadata": {},
   "source": [
    "### 3: Gradual Learning and Boosting\n",
    "\n",
    "- Gradual learning is a heterogeneous ensemble method. \n",
    "\n",
    "- It is based on the iterative learning principle, in which each model attempts to fix the errors from the previous one. \n",
    "\n",
    "- Therefore, this approach uses a sequential model building. \n",
    "\n",
    "#### When to choose:\n",
    "\n",
    "- The Boosting algorithms are a good choice when you have complex problems, which are not getting good results with traditional methods. \n",
    "\n",
    "- Also if you need to apply parallel processing or distributed computing. \n",
    "\n",
    "- And if you have big datasets or high-dimensional categorical features, gradient boosting machine can handle these natively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba9a914",
   "metadata": {},
   "source": [
    "### 4: Stacking\n",
    "\n",
    "- Stacking also works by combining individual estimators, but the combiner is an estimator itself, instead of just an operation. \n",
    "\n",
    "- Stacking can be applied to Classification and Regression. It is also a heterogeneous ensemble method.\n",
    "\n",
    "#### When to choose:\n",
    "\n",
    "- Stacking is a good choice when you have already tried Voting or Averaging but results are not so good. \n",
    "\n",
    "- Also if you have built models which perform well in different cases, as the second-layer estimator could identify those patterns."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
