{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff071ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61139b35",
   "metadata": {},
   "source": [
    "### Pandas and Excel:\n",
    "Pandas treats excel workbook as a `Dictionary` where-\n",
    "\n",
    "1.`key = Sheete name`\n",
    "\n",
    "2.`value = DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c93d163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2016', '2017']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Before importing the excel file you can see the sheet names of that excel file\n",
    "\n",
    "pd.ExcelFile('fcc-new-coder-survey.xlsx').sheet_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446ca15a",
   "metadata": {},
   "source": [
    "### EX 1:\n",
    "\n",
    "In this exercise, you'll create a data frame from a \"base case\" Excel file: one with a `single sheet` of tabular data. The `fcc_survey.xlsx` file here has a sample of responses from `FreeCodeCamp's` annual New Developer Survey. This survey asks participants about their demographics, education, work and home life, plus questions about how they're learning to code. Let's load all of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "153dd47a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read spreadsheet and assign it to survey_responses\n",
    "survey_responses = pd.read_excel('fcc-new-coder-survey.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c3797d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the head of the data frame\n",
    "#survey_responses.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bd698b",
   "metadata": {},
   "source": [
    "### Ex 2: Load a portion of a spreadsheet\n",
    "\n",
    "`Spreadsheets` meant to be read by people often have `multiple tables`, e.g., a small business might keep an inventory workbook with tables for different product types on a `single sheet`. Even tabular data may have `header rows` of `metadata`, like the `New Developer Survey` data here. While the metadata is useful, we don't want it in a data frame.\n",
    "\n",
    "You'll use read_excel()'s `skiprows` keyword to get just the data. You'll also create a `string` to pass to `usecols` to get only columns `AD and AW through BA`, about future job goals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ad00858",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We can see from opening the spreadsheet in excel, the first two rows there are metadata\n",
    "## Load fcc_survey_headers.xlsx', setting skiprows and usecols to skip the first two rows of metadata \n",
    "\n",
    "survey_responses = pd.read_excel(\"fcc-new-coder-survey.xlsx\", skiprows = 2)\n",
    "#survey_responses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818a75f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a single string, specifying pandas usecols argument to get only columns AD and AW through BA, about future job goals. \n",
    "\n",
    "col_string = \"AD, AW:BA\"\n",
    "\n",
    "survey_responses = pd.read_excel(\"fcc-new-coder-survey.xlsx\", skiprows = 2, usecols = col_string)\n",
    "#survey_responses.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be946f1b",
   "metadata": {},
   "source": [
    "### Getting data from multiple worksheets\n",
    "\n",
    "An Excel workbook may contain `multiple sheets` of related data. The New Developer Survey response workbook has sheets for different years which are `2016 and 2017`. \n",
    "\n",
    "### Ex 3: Select a single sheet\n",
    "\n",
    "Because `read_excel()` loads only the first sheet by `default`, you've already gotten survey responses for 2016. Now, you'll create a data frame of 2017 responses using read_excel()'s `sheet_name` argument in a couple different ways.\n",
    "\n",
    "1.Create a data frame from the second workbook sheet by passing the sheet's `position` to sheet_name.\n",
    "\n",
    "2.Create a data frame from the 2017 sheet by providing the sheet's `name` to read_excel()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecdb932c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>AttendedBootcamp</th>\n",
       "      <th>BootcampFinish</th>\n",
       "      <th>BootcampLoanYesNo</th>\n",
       "      <th>BootcampName</th>\n",
       "      <th>BootcampRecommend</th>\n",
       "      <th>ChildrenNumber</th>\n",
       "      <th>CityPopulation</th>\n",
       "      <th>CodeEventConferences</th>\n",
       "      <th>CodeEventDjangoGirls</th>\n",
       "      <th>...</th>\n",
       "      <th>ResourcePluralSight</th>\n",
       "      <th>ResourceSkillCrush</th>\n",
       "      <th>ResourceStackOverflow</th>\n",
       "      <th>ResourceTreehouse</th>\n",
       "      <th>ResourceUdacity</th>\n",
       "      <th>ResourceUdemy</th>\n",
       "      <th>ResourceW3Schools</th>\n",
       "      <th>SchoolDegree</th>\n",
       "      <th>SchoolMajor</th>\n",
       "      <th>StudentDebtOwe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>more than 1 million</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>some college credit, no degree</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>less than 100,000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>some college credit, no degree</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>more than 1 million</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>high school diploma or equivalent (GED)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>between 100,000 and 1 million</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>some college credit, no degree</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>between 100,000 and 1 million</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bachelor's degree</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  AttendedBootcamp  BootcampFinish  BootcampLoanYesNo BootcampName  \\\n",
       "0  27.0               0.0             NaN                NaN          NaN   \n",
       "1  34.0               0.0             NaN                NaN          NaN   \n",
       "2  21.0               0.0             NaN                NaN          NaN   \n",
       "3  26.0               0.0             NaN                NaN          NaN   \n",
       "4  20.0               0.0             NaN                NaN          NaN   \n",
       "\n",
       "   BootcampRecommend  ChildrenNumber                 CityPopulation  \\\n",
       "0                NaN             NaN            more than 1 million   \n",
       "1                NaN             NaN              less than 100,000   \n",
       "2                NaN             NaN            more than 1 million   \n",
       "3                NaN             NaN  between 100,000 and 1 million   \n",
       "4                NaN             NaN  between 100,000 and 1 million   \n",
       "\n",
       "   CodeEventConferences  CodeEventDjangoGirls  ...  ResourcePluralSight  \\\n",
       "0                   NaN                   NaN  ...                  NaN   \n",
       "1                   NaN                   NaN  ...                  NaN   \n",
       "2                   NaN                   NaN  ...                  NaN   \n",
       "3                   NaN                   NaN  ...                  NaN   \n",
       "4                   NaN                   NaN  ...                  NaN   \n",
       "\n",
       "   ResourceSkillCrush  ResourceStackOverflow  ResourceTreehouse  \\\n",
       "0                 NaN                    NaN                NaN   \n",
       "1                 NaN                    1.0                NaN   \n",
       "2                 NaN                    NaN                NaN   \n",
       "3                 NaN                    1.0                NaN   \n",
       "4                 NaN                    1.0                NaN   \n",
       "\n",
       "   ResourceUdacity  ResourceUdemy  ResourceW3Schools  \\\n",
       "0              NaN            1.0                1.0   \n",
       "1              NaN            1.0                1.0   \n",
       "2              1.0            1.0                NaN   \n",
       "3              NaN            NaN                NaN   \n",
       "4              NaN            NaN                NaN   \n",
       "\n",
       "                              SchoolDegree             SchoolMajor  \\\n",
       "0           some college credit, no degree                     NaN   \n",
       "1           some college credit, no degree                     NaN   \n",
       "2  high school diploma or equivalent (GED)                     NaN   \n",
       "3           some college credit, no degree                     NaN   \n",
       "4                        bachelor's degree  Information Technology   \n",
       "\n",
       "   StudentDebtOwe  \n",
       "0             NaN  \n",
       "1             NaN  \n",
       "2             NaN  \n",
       "3             NaN  \n",
       "4             NaN  \n",
       "\n",
       "[5 rows x 98 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create df from second worksheet by referencing its position\n",
    "\n",
    "responses_2017 = pd.read_excel(\"fcc-new-coder-survey.xlsx\",sheet_name = 1, skiprows = 2)\n",
    "responses_2017.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b9a7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data frame from the 2017 sheet by providing the sheet's name to read_excel().\n",
    "\n",
    "responses_2017 = pd.read_excel(\"fcc-new-coder-survey.xlsx\",sheet_name = \"2017\", skiprows = 2)\n",
    "#responses_2017.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e3c3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses_2017[\"HasDebt\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07889e8d",
   "metadata": {},
   "source": [
    "###  Select multiple sheets\n",
    "\n",
    "So far, you've read Excel files `one sheet` at a time, which lets you customize import arguments for each sheet. But if an Excel file has some sheets that you want loaded with the same parameters, you can get them in one go by passing a `list` of their `names` or `indices` to read_excel()'s `sheet_name` keyword. To get them all, pass `None`. You'll practice both methods to get data from fcc_survey.xlsx, which has multiple sheets of similarly-formatted data.\n",
    "\n",
    "Workbooks meant primarily for human readers, not machines, may store data about a single subject across `multiple` sheets. For example, a file may have a different sheet of transactions for each region or year in which a business operated.\n",
    "\n",
    "The FreeCodeCamp New Developer Survey file is set up similarly, with samples of responses from different years in different sheets. Your task here is to compile them in one data frame for analysis.\n",
    "\n",
    "After the Ex 4, All sheets will be read into the ordered dictionary `all_data`, where `sheet names` are `keys` and `data frames` are `values`, so you can get data frames with the `values()` method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e5b28f",
   "metadata": {},
   "source": [
    "### Ex 4:\n",
    "\n",
    "1.Load both the 2016 and 2017 sheets by `name` with a `list` and one call to read_excel().\n",
    "\n",
    "2.Load the 2016 sheet by its `position` (0) and 2017 by `name`. Note the sheet names in the result.\n",
    "\n",
    "3.Load all sheets in the Excel file `without` listing them all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ececed",
   "metadata": {},
   "outputs": [],
   "source": [
    "## all the datasets Below will give the same answer, we tried to load in different ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb95c6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load both the 2016 and 2017 sheets by name with a list and one call to read_excel().\n",
    "\n",
    "all_data = pd.read_excel(\"fcc-new-coder-survey.xlsx\", skiprows = 2, sheet_name = [\"2016\", \"2017\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d399cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the 2016 sheet by its position (0) and 2017 by name. Note the sheet names in the result.\n",
    "\n",
    "all_data = pd.read_excel(\"fcc-new-coder-survey.xlsx\", skiprows = 2, sheet_name = [0, \"2017\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7b73f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load all sheets in the Excel file without listing them all.\n",
    "\n",
    "all_data = pd.read_excel(\"fcc-new-coder-survey.xlsx\", skiprows = 2, sheet_name = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12f22130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## We can confirm that our all_data is a dictionary\n",
    "\n",
    "type(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00999dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the sheet names in all_survey_data\n",
    "\n",
    "all_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d98815f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View all the data frames \n",
    "all_data.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d479972",
   "metadata": {},
   "source": [
    "### Ex 5: \n",
    "\n",
    "To get the dataframes we need to `iterate` through the dictionary `all_data.values()`, to get all the dataframes you need to do following steps ---\n",
    "\n",
    "1.Create an `empty` data frame, give it a variable name.\n",
    "\n",
    "2.Set up a for loop to `iterate` through the `values` in the `all_data` dictionary.\n",
    "\n",
    "3.`Append` each data frame to the empty dataframe and reassign the result to the same variable name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c9a1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty data frame, give it a variable name.\n",
    "\n",
    "all_dataframes = pd.DataFrame()\n",
    "\n",
    "# Set up a for loop to iterate through the values in the all_data dictionary.\n",
    "\n",
    "for df in all_data.values():\n",
    "    \n",
    "    # Print the number of rows being added\n",
    "    print(\"Adding {} rows\".format(df.shape[0]))\n",
    "    \n",
    "    # Append each data frame to the empty dataframe and reassign the result to the same variable name.\n",
    "    all_dataframes = all_dataframes.append(df)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012a9abb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_dataframes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9c03c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating a dataset for our next example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12dfd2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_responses.loc[survey_responses[\"HasDebt\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652483e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_responses['AttendedBootcamp'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f0ba33",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_responses_new = survey_responses.dropna(subset = [\"HasDebt\", 'AttendedBootcamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aba8c04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fcc_survey_subset = survey_responses_new[['ID.x', 'AttendedBootcamp', 'HasDebt', 'HasFinancialDependents', 'HasHomeMortgage', 'HasStudentDebt']]\n",
    "fcc_survey_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19501422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determining the name of the file\n",
    "file_name = 'fcc_survey_subset.xlsx'\n",
    "  \n",
    "# saving the excel file\n",
    "fcc_survey_subset.to_excel(file_name, index = False)\n",
    "print('DataFrame is written to Excel File successfully.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aae85cb",
   "metadata": {},
   "source": [
    "### Set Boolean columns\n",
    "\n",
    "Datasets may have columns that are most accurately modeled as `Boolean` values. However, pandas usually loads these as `floats` by `default`, since defaulting to `Booleans` may have undesired effects like turning `NA` values into `Trues`. `fcc_survey_subset.xlsx` contains a string `ID` column and several `True/False` columns indicating `financial stressors`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2fec90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "survey_data = pd.read_excel(\"fcc_survey_subset.xlsx\")\n",
    "survey_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ee81a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ba4cde",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Count NA values in each column of survey_data with isna() and sum()\n",
    "## Note which columns besides ID.x, if any, have zero NAs.\n",
    "\n",
    "survey_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac6fba2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## We can see HasDebt and AttendedBootcamp columns has zero NAs\n",
    "\n",
    "# Set read_excel()'s dtype argument to load the HasDebt and AttendedBootcamp column as Boolean data.\n",
    "\n",
    "survey_data = pd.read_excel(\"fcc_survey_subset.xlsx\", dtype = {\"HasDebt\": bool, \"AttendedBootcamp\": bool})\n",
    "survey_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a93e9a",
   "metadata": {},
   "source": [
    "### Set custom true/false values\n",
    "\n",
    "In Boolean columns, pandas automatically `recognizes` certain values, like `\"TRUE\" and 1`, as `True`, and others, like `\"FALSE\" and 0`, as `False`. Some datasets, like survey data, can use `unrecognized` values, such as `\"Yes\" and \"No\"`. Unrecognized values in a Boolean column are also changed to `True`.\n",
    "\n",
    "For practice purposes, some Boolean columns in the New Developer Survey have been coded this way. \n",
    "\n",
    "Use `read_excel()` 's `true_values` argument to set custom `True` values . Use `false_values` to set custom `False` values. Each takes a `list` of values to treat as `True / False` , respectively. Custom True / False values are only `applied` to columns set as `Boolean`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7888a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load file with Yes as a True value and No as a False value\n",
    "survey_subset = pd.read_excel(\"fcc_survey_subset.xlsx\",\n",
    "                              dtype={\"HasDebt\": bool,\n",
    "                              \"AttendedBootcamp\": bool},\n",
    "                              true_values = [\"Yes\"],\n",
    "                              false_values = [\"No\"])\n",
    "\n",
    "# View the data\n",
    "survey_subset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea72b56e",
   "metadata": {},
   "source": [
    "### Modifying imports: Parsing dates\n",
    "\n",
    "pandas does not infer that columns contain datetime data; it interprets them as object or string data unless told otherwise. Correctly modeling datetimes is easy when they are in a standard format -- we can use the parse_dates argument to tell read_excel() to read columns as datetime data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ed1722",
   "metadata": {},
   "source": [
    "### Ex 6:\n",
    "\n",
    "The New Developer Survey responses contain some columns with easy-to-parse timestamps. In this exercise, you'll make sure they're the right data type.\n",
    "\n",
    "1.Load `fcc-new-coder-survey.xlsx`, making sure that the `Part1StartTime` column is parsed as `datetime` data\n",
    "\n",
    "2.View the first few values of the `survey_data.Part1StartTime` to make sure it contains `datetimes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f89142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read spreadsheet and assign it to survey_responses\n",
    "survey_responses = pd.read_excel('fcc-new-coder-survey.xlsx', skiprows = 2)\n",
    "#survey_responses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75181df",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_responses[\"Part1StartTime\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78c55eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We can see that this dates are count as an object\n",
    "## We need to convert them as datetime data\n",
    "\n",
    "survey_responses = pd.read_excel('fcc-new-coder-survey.xlsx', skiprows = 2, parse_dates = [\"Part1StartTime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b90ea3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the first few values of the survey_data.Part1StartTime to make sure it contains datetimes.\n",
    "survey_responses[\"Part1StartTime\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed57d86",
   "metadata": {},
   "source": [
    "### Get datetimes from multiple columns\n",
    "\n",
    "Sometimes, datetime data is `split` across columns. A `dataset` might have a `date` and a `time` column, or a `date` may be split into `year, month, and day` columns.\n",
    "\n",
    "### Ex 7:\n",
    "\n",
    "A column in the `datetime` dataset has been split so that dates are in one column, `Part2StartDate`, and times are in another, `Part2StartTime`. Your task is to use read_excel()'s parse_dates argument to combine them into one datetime column with a new name.\n",
    "\n",
    "1.Create a dictionary, `datetime_cols` indicating that the new column `Part2Start` should consist of `Part2StartDate` and `Part2StartTime`\n",
    "\n",
    "2.Load the `datetime` excel file, supplying the dictionary to the `parse_dates` argument to create a new `Part2Start` column.\n",
    "\n",
    "3.Examine survey_data's Part2EndTime column to see the data type and date format. Choose the code that describes the date format in Part2EndTime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557b6be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading the excel file\n",
    "\n",
    "survey_dates = pd.read_excel(\"datetime.xlsx\")\n",
    "survey_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354066fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_dates.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0c4e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "## we can see that all of the dates are objects here we need to change it to date time object\n",
    "\n",
    "## But first we need to--\n",
    "# Create a dictionary, indicating that the column Part2StartTime should consist of Part2StartDate and Part2StartTime\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1350cea8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Load the datetime excel file, \n",
    "## Supplying the dictionary to the parse_dates argument \n",
    "## Part1StartTime, Part1EndTime and to create a new Part2Start column\n",
    "\n",
    "\n",
    "survey_date = pd.read_excel(\"datetime.xlsx\", parse_dates = [\"Part1StartTime\", \"Part1EndTime\", \n",
    "                                                            ['Part2StartDate', 'Part2StartTime']])\n",
    "survey_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887f4087",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_date.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39041714",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_date[\"Part2StartTime\"] = survey_date[\"Part2StartDate_Part2StartTime\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f34060",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_date= survey_date.drop(\"Part2StartDate_Part2StartTime\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bef94d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "survey_date.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad092f4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c78e1f91",
   "metadata": {},
   "source": [
    "### Parse non-standard date formats\n",
    "\n",
    "So far, you've parsed dates that pandas could interpret `automatically`. But if a date is in a `non-standard` format, like `19991231` for `December 31, 1999`, it can't be parsed at the import stage. Instead, use `pd.to_datetime()` to convert strings to dates after import.\n",
    "\n",
    "The New Developer Survey data has been loaded as survey_data but contains an unparsed datetime field. We'll use to_datetime() to convert it, passing in the column to convert and a string representing the date format used.\n",
    "\n",
    "For more on date format codes, see this reference: https://strftime.org/. Some common codes are `year (%Y), month (%m), day (%d), hour (%H), minute (%M), and second (%S)`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d96cd16",
   "metadata": {},
   "source": [
    "### Ex 8:\n",
    "\n",
    "1.Examine `survey_data's` `Part2EndTime` column to see the `data type` and `date format`. Choose the code that describes the date format in Part2EndTime.\n",
    "\n",
    "2.`Parse` Part2EndTime using `pd.to_datetime()`, the format keyword argument, and the `format` string you just identified. Assign the result back to the `Part2EndTime` column.\n",
    "\n",
    "3.Print the head of Part2EndTime to confirm the column now contains datetime values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337339a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine survey_data's Part2EndTime column to see the data type and date format. \n",
    "# Choose the code that describes the date format in Part2EndTime.\n",
    "\n",
    "survey_date[\"Part2EndTime\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a56b15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## The date format is --- \"%m%d%Y %H:%M:%S\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d962680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse Part2EndTime using pd.to_datetime(), \n",
    "# the format keyword argument, and the format string you just identified. Assign the result back to the Part2EndTime column.\n",
    "\n",
    "survey_date[\"Part2EndTime\"] = pd.to_datetime(survey_date[\"Part2EndTime\"], format = \"%m%d%Y %H:%M:%S\")\n",
    "\n",
    "# Print the head of Part2EndTime to confirm the column now contains datetime values.\n",
    "\n",
    "survey_date[\"Part2EndTime\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ef6c01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bd916f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69465ce1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6ffa3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e7f12d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e2b2f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3989be6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ece216",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8721e020",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f535a32f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243cbdc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658f8680",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed612bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffadbaef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e203df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddc5720",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ce6cee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca05c52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363879f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe76749",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
